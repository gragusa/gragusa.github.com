<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">

    <meta http-equiv="X-UA-Compatible" content="IE=edge,partials=1">
<meta name="description" content="">
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1 minimal-ui">

<meta name="description" content="">
<meta name="keywords" content="">




<meta name="twitter:card" content="summary">

<meta name="twitter:site" content="@giuragusa">
<meta name="twitter:title" content="Resources : gragusa.org">
<meta name="twitter:creator" content="@gragusa">
<meta name="twitter:description" content="">
<meta name="twitter:image:src" content="">
<meta name="twitter:domain" content="gragusa.org">



    <base href="http://gragusa.org/">
    <title> Resources </title>
    <link rel="canonical" href="http://gragusa.org/code/">
    

        <link rel="stylesheet" href="http://gragusa.org/css/stylesheet-min.css" />
	<link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet">
    <link rel="stylesheet" href="http://gragusa.org/css/academicons.min.css">
    




 <script src="//code.jquery.com/jquery-1.8.3.min.js"></script>
 <script type="text/javascript" src="javascripts/bigfoot.js"></script>
 <script type="text/javascript">$.bigfoot();</script>







<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
  tex2jax: {
      inlineMath: [['$','$'], ['\\(','\\)']],
      displayMath: [['$$','$$'], ['\[','\]']]}

  });
</script>
<script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    <link href="https://fonts.googleapis.com/css?family=Roboto|Roboto+Slab" rel="stylesheet">
<link rel="shortcut icon" href="http://gragusa.org/favicon.ico" type="image/x-icon" />
  <link rel="apple-touch-icon" href="http://gragusa.org/apple-touch-icon.png" />
  <link rel="apple-touch-icon" sizes="57x57" href="http://gragusa.org/apple-touch-icon-57x57.png" />
  <link rel="apple-touch-icon" sizes="72x72" href="http://gragusa.org/apple-touch-icon-72x72.png" />
  <link rel="apple-touch-icon" sizes="76x76" href="http://gragusa.org/apple-touch-icon-76x76.png" />
  <link rel="apple-touch-icon" sizes="114x114" href="http://gragusa.org/apple-touch-icon-114x114.png" />
  <link rel="apple-touch-icon" sizes="120x120" href="http://gragusa.org/apple-touch-icon-120x120.png" />
  <link rel="apple-touch-icon" sizes="144x144" href="http://gragusa.org/apple-touch-icon-144x144.png" />
  <link rel="apple-touch-icon" sizes="152x152" href="http://gragusa.org/apple-touch-icon-152x152.png" />
  <link rel="apple-touch-icon" sizes="180x180" href="http://gragusa.org/apple-touch-icon-180x180.png" />


    <link rel="shortcut icon" href="http://gragusa.org/favicon.ico" type="image/x-icon" />
    <link rel="apple-touch-icon" href="http://gragusa.org/apple-touch-icon.png" />
</head>

<body lang="en" itemscope itemtype="http://schema.org/Article">
<div id="topbar">
<div class="wrapper">
  <header>

  <nav class="navbar">
  <ul>
    <li><a href="http://gragusa.org/">Giuseppe Ragusa</a></li>
    
    
    <li><span> <a class="" href="http://gragusa.org/publications">Publications </a></span>
      
    <li><span> <a class="" href="http://gragusa.org/code">Code </a></span>
      
    <li><span> <a class="" href="http://gragusa.org/teaching">Teaching </a></span>
      
    <li><span> <a class="" href="http://gragusa.org/blog">Blog </a></span>
      
  </ul>  
</nav>


  
  </header>
</div>
</div>

<div class="wrapper">
  <div class="units-row">
    <div class="unit-centered unit-80">
      <article class="post" id="content">
        

<p>On this page, I will keep a running list of computation/programming projects I work on from time to time.</p>

<p>When it comes to coding, my interests range from the estimation of nonlinear moment condition models, approximate Bayesian inference, large optimization problems, high-performance computing in econometrics and finance, and big data application to time series econometrics. Below you will find a list of packages I have recently written. For details on each package visit my <a href="http://github.com/gragusa">github</a> and/or visit the package page. For code related to published paper, visit the publication section.</p>

<h1 id="julia-packages">Julia Packages</h1>

<p>Notice that some of the Julia packages are &ldquo;registered&rdquo;, meaning that you can install them from Julia by <code>Pkg.add</code>-ing them. Others are at an early stage and are not yet registered. To install these packages use <code>Pkg.clone</code>.</p>

<h2 id="covariancematrices-jl-http-github-com-gragusa-covariancematrices-jl"><a href="http:://github.com/gragusa/CovarianceMatrices.jl"><code>CovarianceMatrices.jl</code></a></h2>

<p><a href="https://raw.githubusercontent.com/gragusa/CovarianceMatrices.jl/master/LICENSE.md"><img src="https://img.shields.io/badge/license-MIT-blue.svg" alt="license" /></a>  <a href="http://pkg.julialang.org/?pkg=CovarianceMatrices&amp;ver=0.5"><img src="http://pkg.julialang.org/badges/CovarianceMatrices_0.5.svg" alt="CovarianceMatrices" /></a> <a href="https://travis-ci.org/gragusa/CovarianceMatrices.jl"><img src="https://travis-ci.org/gragusa/CovarianceMatrices.jl.svg?branch=master" alt="Build Status" /></a> <a href="https://coveralls.io/github/gragusa/CovarianceMatrices.jl?branch=master"><img src="https://coveralls.io/repos/gragusa/CovarianceMatrices.jl/badge.svg?branch=master&amp;service=github" alt="Coverage Status" /></a></p>

<p><code>CovarianceMatrices</code> is a package for estimating variance-covariance matrices in situations where the standard assumptions of independence are violated. It provides heteroskedasticity consistent (HC); heteroskedasticity and autocorrelation consistent (HAC); and cluster-robust (CRVE) estimators of the variance matrices. An interface for <code>GLM.jl</code> is given so that they can be integrated easily into the standard regression analysis flow. It is also easy to incorporate these estimators into new inferential procedures or applications.</p>


<div class="highlight"><pre><code class="language-julia" data-lang="julia"><span></span><span class="k">using</span> <span class="n">CovarianceMatrices</span>
<span class="c">## Simulated AR(1) and estimate it using OLS</span>
<span class="n">srand</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">(</span><span class="kt">Float64</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">rho</span> <span class="o">=</span> <span class="mf">0.8</span>
<span class="n">y</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">randn</span><span class="p">()</span>
<span class="k">for</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">2</span><span class="o">:</span><span class="mi">100</span>
  <span class="n">y</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">rho</span> <span class="o">*</span> <span class="n">y</span><span class="p">[</span><span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">randn</span><span class="p">()</span>
<span class="k">end</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">DataFrame</span><span class="p">(</span><span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="mi">2</span><span class="o">:</span><span class="mi">100</span><span class="p">],</span> <span class="n">yl</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="mi">1</span><span class="o">:</span><span class="mi">99</span><span class="p">])</span>
<span class="n">AR1</span>  <span class="o">=</span> <span class="n">fit</span><span class="p">(</span><span class="n">GeneralizedLinearModel</span><span class="p">,</span> <span class="n">y</span><span class="o">~</span><span class="n">yl</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">Normal</span><span class="p">())</span>

<span class="c">## Truncated Kernel with optimal bandwidth</span>
<span class="n">vcov</span><span class="p">(</span><span class="n">AR1</span><span class="p">,</span> <span class="n">TruncatedKernel</span><span class="p">())</span>
</code></pre></div>



<h2 id="divergences-jl-http-github-com-gragusa-divergences-jl"><a href="http://github.com/gragusa/Divergences.jl"><code>Divergences.jl</code></a></h2>

<p><a href="https://raw.githubusercontent.com/gragusa/Divergences.jl/master/LICENSE.md"><img src="https://img.shields.io/badge/license-MIT-blue.svg" alt="license" /></a> <a href="http://pkg.julialang.org/detail/Divergences.html"><img src="http://pkg.julialang.org/badges/Divergences_0.5.svg" alt="Pkg" /></a> <a href="http://pkg.julialang.org/detail/Divergences.html"><img src="http://pkg.julialang.org/badges/Divergences_0.6.svg" alt="Pkg" /></a> <a href="https://travis-ci.org/gragusa/Divergences.jl"><img src="https://travis-ci.org/gragusa/Divergences.jl.svg?branch=master" alt="Build Status" /></a> <a href="https://coveralls.io/github/gragusa/Divergences.jl?branch=master"><img src="https://coveralls.io/repos/github/gragusa/Divergences.jl/badge.svg?branch=master" alt="Coverage Status" /></a></p>

<p><code>Divergences</code> is a Julia package that makes it easy to evaluate divergence measures between two vectors. The package allows calculating the gradient and the diagonal of the Hessian of several divergences.</p>

<ul>
<li>Komunjer, I.; Ragusa, G. &ldquo;Existence and characterization of conditional density projections.&rdquo; Econometric Theory 2016, 32, 947–987.</li>
</ul>

<!--
A divergence between two vectors of probabilities; $p := (p\_1, p\_2,\ldots,p\_n)$ and $q := (q\_1, q\_2,\ldots,q\_n)$ is defined as
$$ D(p,q)= \sum\_{i=1}^{n} \phi \left(\frac{p\_{i}}{q\_{i}}\right)p\_{i} $$ where $\phi$ is function that satisfies the following:

1. is twice continuously differentiable on `$ (0, +\infty) $`;
2. is strictly convex on $(0, +\infty)$;
3. $\phi(1) = \phi'(1) = 0$;
4. $\lim\_{u->0^+} \phi'(u) < 0$;
5. $\lim\_{u->+\infty} \phi'(u) > 0$.

An very general family of divergences is the Cressie-Read family[^1]. The class is indexed by a real parameter $\alpha$ and it is defined as
<div>
$$
\phi\_{\alpha}(u)=\begin{cases}
\frac{u^{\alpha+1}-1}{a(a+1)}-\frac{1}{a}u+\frac{1}{a} \& u>0 \\\\[2ex]
\frac{1}{a+1} \& u=0
\end{cases}.
$$
</div>

The package defines a `Divergence` type with the following suptypes:

* Kullback-Leibler divergence `KullbackLeibler`
* Chi-square distance `ChiSquared`
* Reverse Kullback-Leibler divergence `ReverseKullbackLeibler`
* Cressie-Read divergences `CressieRead`

These divergences differ from the equivalent ones defined in the `Distances` package because they are normalized. Also, the package provides methods for calculating their gradient and the (diagonal elements of the) Hessian matrix.

The constructors for the types above are straightforward
```julia
KullbackLeibler()
ChiSqaured()
ReverseKullbackLeibler()
```
The constructor for `CressieRead` is
```julia
CR(::Real)
```
The Hellinger divergence is obtained by `CR(-1/2)`. For a certain value of `alpha`, `CressieRead` correspond to a divergence that has a specific type defined. For instance `CR(1)` is equivalent to `ChiSquared` although the underlying code for evaluation and calculation of the gradient and Hessian are different. -->


<div class="highlight"><pre><code class="language-julia" data-lang="julia"><span></span><span class="k">using</span> <span class="n">Divergences</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="n">q</span> <span class="o">=</span> <span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="n">scale!</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="n">sum</span><span class="p">(</span><span class="n">p</span><span class="p">))</span>
<span class="n">scale!</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="n">sum</span><span class="p">(</span><span class="n">q</span><span class="p">))</span>
<span class="n">evaluate</span><span class="p">(</span><span class="n">CressieRead</span><span class="p">(</span><span class="o">-.</span><span class="mi">5</span><span class="p">),</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span>
</code></pre></div>



<h2 id="genoud-jl-http-github-org-gragusa-genoud-jl"><a href="http://github.org/gragusa/Genoud.jl"><code>Genoud.jl</code></a></h2>

<p><a href="https://raw.githubusercontent.com/gragusa/Genoud.jl/master/LICENSE.md"><img src="https://img.shields.io/badge/license-GPL3.0+-blue.svg" alt="" /></a> <a href="code/"><img src="https://img.shields.io/badge/Julia-unregistered-red.svg" alt="" /></a></p>

<p>GENetic Optimization Using Derivative.</p>

<div class="units-row">

<div class="unit-65">



<div class="highlight"><pre><code class="language-julia" data-lang="julia"><span></span><span class="k">using</span> <span class="n">Genoud</span>
<span class="k">using</span> <span class="n">Calculus</span>
<span class="k">function</span> <span class="n">f8</span><span class="p">(</span><span class="n">xx</span><span class="p">)</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">xx</span>
    <span class="o">-</span><span class="n">x</span><span class="o">*</span><span class="n">sin</span><span class="p">(</span><span class="o">√</span><span class="n">abs</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="o">-</span> <span class="n">y</span><span class="o">*</span><span class="n">sin</span><span class="p">(</span><span class="o">√</span><span class="n">abs</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
<span class="k">end</span>

<span class="k">function</span> <span class="n">gr!</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">stor</span><span class="p">)</span>  
    <span class="n">stor</span><span class="p">[</span><span class="o">:</span><span class="p">]</span> <span class="o">=</span> <span class="n">Calculus</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">f8</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="k">end</span>

<span class="n">dom</span> <span class="o">=</span> <span class="n">Genoud</span><span class="o">.</span><span class="n">Domain</span><span class="p">([</span><span class="o">-</span><span class="mi">500</span>  <span class="mf">500.</span><span class="p">;</span>
                     <span class="o">-</span><span class="mf">500.</span> <span class="mf">500.</span><span class="p">])</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">Genoud</span><span class="o">.</span><span class="n">genoud</span><span class="p">(</span><span class="n">f8</span><span class="p">,</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">],</span>
                    <span class="n">sizepop</span> <span class="o">=</span> <span class="mi">5000</span><span class="p">,</span>
                    <span class="n">sense</span> <span class="o">=</span> <span class="o">:</span><span class="n">Min</span><span class="p">,</span>
                    <span class="n">domains</span> <span class="o">=</span> <span class="n">dom</span><span class="p">)</span>
</code></pre></div>



</div>

<div class="unit-35">

<figure>
    <img src="fig/f8.png"  />
    <figcaption>
        <h4>Surface plot of $$f(x_1, x_2) = -\sum_{i=1}^2 x_i \sin(\sqrt{|x_i|}).$$ This function is minimized at $x_1^*  \approx 420.968$ and $x_2^* \approx 420.968$. At the minima, $f(x_1^*, x_2^*) = -837.9$.
        <p></p>
        Source: Yao, Xin, Yong Liu, and Guangming Lin. "Evolutionary programming made faster." IEEE Transactions on Evolutionary computation 3, no. 2 (1999): 82-102.</h4>
    </figcaption>
</figure>


</div>
</div>


<div class="highlight"><pre><code class="language-julia" data-lang="julia"><span></span><span class="n">Results</span> <span class="n">of</span> <span class="n">Genoud</span> <span class="n">Optimization</span> <span class="n">Algorithm</span>
 <span class="o">*</span> <span class="n">Minimizer</span><span class="o">:</span> <span class="p">[</span><span class="mf">420.96874636091724</span><span class="p">,</span><span class="mf">420.9687462145861</span><span class="p">]</span>
 <span class="o">*</span> <span class="n">Minimum</span><span class="o">:</span> <span class="o">-</span><span class="mf">8.379658e+02</span>
 <span class="o">*</span> <span class="n">Pick</span> <span class="n">generation</span><span class="o">:</span> <span class="mi">20</span>
 <span class="o">*</span> <span class="n">Convergence</span><span class="o">:</span> <span class="kc">true</span>
   <span class="o">*</span> <span class="o">|</span><span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="o">&#39;</span><span class="p">)</span><span class="o">|</span> <span class="o">/</span> <span class="o">|</span><span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">|</span> <span class="o">&lt;</span> <span class="mf">1.0e-03</span><span class="o">:</span> <span class="kc">true</span>
   <span class="o">*</span> <span class="kt">Number</span> <span class="n">of</span> <span class="n">Generations</span><span class="o">:</span> <span class="mi">27</span>
</code></pre></div>



<h2 id="csminwel-jl-http-github-org-gragusa-csminwel-jl"><a href="http://github.org/gragusa/CsminWel.jl"><code>CsminWel.jl</code></a></h2>

<p><a href="https://raw.githubusercontent.com/gragusa/CsminWel.jl/master/LICENSE.md"><img src="https://img.shields.io/badge/license-BSD3-blue.svg" alt="" /></a>  <a href="code/"><img src="https://img.shields.io/badge/Julia-unregistered-red.svg" alt="" /></a> <a href="https://travis-ci.org/gragusa/CsminWel.jl"><img src="https://travis-ci.org/gragusa/CsminWel.jl.svg?branch=master" alt="Build Status" /></a> <a href="https://coveralls.io/github/gragusa/CsminWel.jl?branch=master"><img src="https://coveralls.io/repos/gragusa/CsminWel.jl/badge.svg?branch=master&amp;service=github" alt="Coverage Status" /></a> <a href="http://codecov.io/github/gragusa/CsminWel.jl?branch=master"><img src="http://codecov.io/github/gragusa/CsminWel.jl/coverage.svg?branch=master" alt="codecov.io" /></a></p>

<p>This package provides an interface to Chris Sims&rsquo; <code>csminwel</code> optimization code. The code borrows from <a href="https://github.com/FRBNY-DSGE/DSGE.jl">DSGE.jl</a>, but it is adapted to be compatibles with the <a href="https://github.com/JuliaOpt/Optim.jl">Optim.jl</a>&rsquo;s API. When the derivative of the minimand is not supplied either Finite Difference of Forward Automatic Differentiation derivatives are automatically used.</p>

<p>From the original author:
&gt; Uses a quasi-Newton method with BFGS update of the estimated inverse hessian. It is robust against certain pathologies common on likelihood functions. It attempts to be robust against &ldquo;cliffs&rdquo;, i.e. hyperplane discontinuities, though it is not really clear whether what it does in such cases succeeds reliably.</p>

<p>Differently from the solvers in <code>Optim.jl</code>, <code>Csminwel</code> returns an estimate of the inverse of the Hessian at the solution which may be used for standard errors calculations and/or to scale a Monte Carlo sampler.</p>


<div class="highlight"><pre><code class="language-julia" data-lang="julia"><span></span><span class="cm">#=</span>
<span class="cm">Maximizing loglikelihood of logistic models</span>
<span class="cm">=#</span>
<span class="k">using</span> <span class="n">CsminWel</span>
<span class="k">using</span> <span class="n">StatsFuns</span>
<span class="c">## Generate fake data (true coefficient = 0)</span>
<span class="n">srand</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="n">ones</span><span class="p">(</span><span class="mi">200</span><span class="p">)</span> <span class="n">randn</span><span class="p">(</span><span class="mi">200</span><span class="p">,</span><span class="mi">4</span><span class="p">)]</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="n">rand</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="o">?</span> <span class="mf">1.</span> <span class="o">:</span> <span class="mf">0.</span> <span class="k">for</span> <span class="n">j</span> <span class="kp">in</span> <span class="mi">1</span><span class="o">:</span><span class="mi">200</span><span class="p">]</span>

<span class="c">## log-likelihood</span>
<span class="k">function</span> <span class="n">loglik</span><span class="p">(</span><span class="n">beta</span><span class="p">)</span>
    <span class="n">xb</span> <span class="o">=</span> <span class="n">x</span><span class="o">*</span><span class="n">beta</span>
    <span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="n">y</span><span class="o">.*</span><span class="n">xb</span> <span class="o">+</span> <span class="n">log1pexp</span><span class="o">.</span><span class="p">(</span><span class="n">xb</span><span class="p">))</span>
<span class="k">end</span>

<span class="c">## Derivative of loglikelihood</span>
<span class="k">function</span> <span class="n">dloglik</span><span class="p">(</span><span class="n">beta</span><span class="p">)</span>
    <span class="n">xb</span> <span class="o">=</span> <span class="n">x</span><span class="o">*</span><span class="n">beta</span>
    <span class="n">px</span> <span class="o">=</span> <span class="n">logistic</span><span class="o">.</span><span class="p">(</span><span class="n">xb</span><span class="p">)</span>
    <span class="o">-</span><span class="n">x</span><span class="o">&#39;*</span><span class="p">(</span><span class="n">y</span><span class="o">.-</span><span class="n">px</span><span class="p">)</span>
<span class="k">end</span>

<span class="c">## Optim uses a mutating function for deriv</span>
<span class="k">function</span> <span class="n">fg!</span><span class="p">(</span><span class="n">beta</span><span class="p">,</span> <span class="n">stor</span><span class="p">)</span>
    <span class="n">stor</span><span class="p">[</span><span class="o">:</span><span class="p">]</span> <span class="o">=</span> <span class="n">dloglik</span><span class="p">(</span><span class="n">beta</span><span class="p">)</span>
<span class="k">end</span>

<span class="c">## With analytical derivative</span>
<span class="n">res1</span> <span class="o">=</span> <span class="n">optimize</span><span class="p">(</span><span class="n">loglik</span><span class="p">,</span> <span class="n">fg!</span><span class="p">,</span> <span class="n">zeros</span><span class="p">(</span><span class="mi">5</span><span class="p">),</span> <span class="n">BFGS</span><span class="p">())</span>
<span class="n">res2</span> <span class="o">=</span> <span class="n">optimize</span><span class="p">(</span><span class="n">loglik</span><span class="p">,</span> <span class="n">fg!</span><span class="p">,</span> <span class="n">zeros</span><span class="p">(</span><span class="mi">5</span><span class="p">),</span> <span class="n">Csminwel</span><span class="p">())</span>

<span class="c">## With finite-difference derivative</span>
<span class="n">res3</span> <span class="o">=</span> <span class="n">optimize</span><span class="p">(</span><span class="n">loglik</span><span class="p">,</span> <span class="n">zeros</span><span class="p">(</span><span class="mi">5</span><span class="p">),</span> <span class="n">Csminwel</span><span class="p">())</span>

<span class="c">## With forward AD derivative</span>
<span class="n">res4</span> <span class="o">=</span> <span class="n">optimize</span><span class="p">(</span><span class="n">loglik</span><span class="p">,</span> <span class="n">zeros</span><span class="p">(</span><span class="mi">5</span><span class="p">),</span> <span class="n">Csminwel</span><span class="p">(),</span> <span class="n">OptimizationOptions</span><span class="p">(</span><span class="n">autodiff</span><span class="o">=</span><span class="kc">true</span><span class="p">))</span>

<span class="c">## Use approximation to the inverse Hessian for standard errors of estimated parameters</span>
<span class="n">stderr</span> <span class="o">=</span> <span class="o">√</span><span class="n">diag</span><span class="p">(</span><span class="n">res2</span><span class="o">.</span><span class="n">invH</span><span class="p">)</span>
</code></pre></div>



      </article>
    </div>
  </div>
</div>

<hr class="separator">

<div class="wrapper" style="font-size: 0.9em; line-height: 1.05em;">
  <div class="units-row units-padding">
    <div class="unit-40">
      <h3>about</h3>
      <figure class="image-left">
        <img class="avatar" src="http://gragusa.org/files/likelihood.png" height="120" width="120">
      </figure>
      <p>Giuseppe Ragusa teaches in the Department of Economics and Business and in the Business School at Luiss University.
His research is mostly about econometrics.</p>
    </div>
    <div class="unit-30">
      <h3>Where</h3>
      <ul class="compact fa-ul">
        <li><i class="fa-li fa fa-university fa-fw" style="color:#03396c;font-size:80%;padding-top:6px;"></i>Department of Economics and Finance, Luiss University, Rome, Italy.</li>
        <li><i class="fa-li fa fa-envelope fa-fw" style="color:#03396c;font-size:80%;padding-top:6px;"></i><a href='m&#97;il&#116;o&#58;g%7&#50;&#97;g%75s%&#54;1&#64;&#108;u&#105;%73%73&#46;it'>grag&#117;sa&#64;lui&#115;s&#46;it</a></li>
        <li><i class="fa-li fa fa-twitter-square fa-fw" style="color:#03396c;font-size:80%;padding-top:6px;"></i><a href="http://twitter.com/giuragusa">@giuragusa</a> on Twitter.</li>
        <li><i class="fa-li fa fa-github fa-fw" style="color:#03396c;font-size:80%;padding-top:6px;"></i><a href="http://github.com/gragusa">On GitHub</a>.</li>
        <li><i class=""></li>
      </ul>
    </div>
<div class="unit-30">
				<h3>subscribe</h3>
				<p>To receive updates from this site, you can
				subscribe to the <a href="http://gragusa.org/index.xml"><i class="fa fa-rss-square" style="color:#03396c;"></i>&nbsp;RSS feed</a> of all updates to the site in an RSS feed reader</p>
				<h3>search</h3>
				<a id="searchsite">
					<form method="get" action="https://duckduckgo.com/">
				<input type="search" name="q" maxlength="255" placeholder="Search the site">
			<input type="hidden" name="sites" value="gragusa.org"/>
			   <input type="hidden" name="k7" value="#faf8f8"/>
			   <input type="hidden" name="kj" value="#b33"/>
			   <input type="hidden" name="ky" value="#fafafa"/>
			   <input type="hidden" name="kx" value="b"/>
			   <input type="hidden" name="ko" value="-1"/>
			   <input type="hidden" name="k1" value="-1"/>
			   <input type="submit" value="DuckDuckGo Search" style="visibility: hidden;" /></form></a>
			</div>
		</div>
	</div>
</div>


<footer id="footer">
<section class="wrapper small">Powered by <a href="http://gohugo.io">Hugo</a> and <a href="http://imperavi.com/kube/">Kube</a>. &copy; Giuseppe Ragusa 2006&ndash;2017. 
</section>
</footer>


<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-78069-5', 'auto');
  ga('send', 'pageview');

</script>

